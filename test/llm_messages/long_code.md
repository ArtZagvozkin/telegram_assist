
–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ `telegram_bot\handlers.py`:

```python
from __future__ import annotations

from telegram import Update, Message
from telegram.constants import ParseMode
from telegram.ext import (
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

from config import SYSTEM_PROMPT, logger
from llm.base import LLMClient
from storage.base import BaseContextStore
from telegram_bot.utils import convert_to_md_v2, split_md_v2
from telegram_bot.message_adapter import parse_message, to_chat_message


async def send_reply(message: Message, text: str) -> None:
    text = convert_to_md_v2(text)
    for chunk in split_md_v2(text):
        logger.info(chunk)
        await message.reply_text(
            chunk,
            parse_mode=ParseMode.MARKDOWN_V2
        )


def create_handlers(llm_client: LLMClient, context_store: BaseContextStore):
    """
    –§–∞–±—Ä–∏–∫–∞ —Ö–µ–Ω–¥–ª–µ—Ä–æ–≤.
    –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –≤–∏–¥—è—Ç llm_client –∏ context_store —á–µ—Ä–µ–∑ –∑–∞–º—ã–∫–∞–Ω–∏–µ.
    """

    async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        message = update.message
        if message:
            await message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø —á–∞—Ç-–±–æ—Ç, —á–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")

    async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        user = update.effective_user
        message = update.message

        if not user or not message:
            logger.warning("Reset called without proper user/message: %s", update)
            return

        user_id = user.id
        context_store.reset(user_id)

        logger.info("Context reset for user %s", user_id)
        await message.reply_text("–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω üßπ")

    async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        message = update.message
        user = update.effective_user
        if message is None or user is None:
            logger.warning("Update without message or user: %s", update)
            return

        user_id = user.id
        logger.info("User id: %s", user_id)

        # –ü–∞—Ä—Å–∏–º –≤—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        parsed = await parse_message(message)
        user_message = to_chat_message(parsed)

        if user_message is None:
            logger.warning("No text or supported media found, exiting")
            await message.reply_text(
                "–ü–æ–∫–∞ —è –ø–æ–Ω–∏–º–∞—é —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ñ–∞–π–ª—ã –∏ –∞—É–¥–∏–æ üôÇ"
            )
            return

        # –†–∞–±–æ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        context_store.append_message(user_id, user_message)
        history = context_store.get_history(user_id)

        messages_for_llm = [
            {"role": "system", "content": SYSTEM_PROMPT}
        ] + history

        # –ó–∞–ø—Ä–æ—Å –∫ LLM
        try:
            assistant_response = await llm_client.generate(messages_for_llm)
            if not assistant_response:
                logger.error("LLM returned empty text for user %s", user_id)
                await message.reply_text("–ù–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ üòî")
                return

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context_store.append_message(
                user_id,
                {"role": "assistant", "content": assistant_response},
            )

            await send_reply(message, assistant_response)

        except Exception:
            logger.exception(
                "Error while getting response from LLM for user %s", user_id
            )
            await message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

    return [
        CommandHandler("start", start),
        CommandHandler("reset", reset),
        MessageHandler(
            (filters.TEXT & ~filters.COMMAND)
            | filters.PHOTO
            | filters.Document.ALL
            | filters.VOICE
            | filters.AUDIO
            | filters.VIDEO
            | filters.VIDEO_NOTE,
            handle_message,
        ),
    ]
```



–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ `telegram_bot\utils.py`:

```python
from __future__ import annotations

import re
from typing import List, Dict
from config import MAX_TELEGRAM_MESSAGE_LEN

# –ù–∞–±–æ—Ä —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ Telegram —Ç—Ä–µ–±—É–µ—Ç —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –≤ MarkdownV2
MD_V2_SPECIAL_CHARS = set("_*[]()~`>#+-=|{}.!")

# –ü–∞—Ç—Ç–µ—Ä–Ω –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤–∏–¥–∞ #..###### –ó–∞–≥–æ–ª–æ–≤–æ–∫
HEADER_RE = re.compile(r"^(#{1,6})\s+(.*)$")

# –ü–∞—Ç—Ç–µ—Ä–Ω —Å—Å—ã–ª–æ–∫ [text](url) –∏ ![alt](url
LINK_RE = re.compile(r"!?\[([^\]]+)\]\(([^)]+)\)")

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ç–∞–±–ª–∏—Ü
TABLE_ROW_RE = re.compile(r"^\s*\|.*\|?\s*$")
TABLE_SEP_RE = re.compile(r"^\s*\|?(?:\s*:?-+:?\s*\|)+\s*$")

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ñ–æ—Ä–º—É–ª LaTeX-–ø–æ–¥–æ–±–Ω–æ–≥–æ –≤–∏–¥–∞
FORMULA_INLINE_RE = re.compile(r"\$(.+?)\$")
FORMULA_BLOCK_RE = re.compile(r"^\s*\$(.+)\$\s*$")
FORMULA_DBL_BLOCK_RE = re.compile(r"^\s*\$\$(.+)\$\$\s*$")

# –ü–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –¥–ª—è "–∑–∞—â–∏—â—ë–Ω–Ω—ã—Ö" —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ (–∫–æ–¥, —Å—Å—ã–ª–∫–∏, –≥–æ—Ç–æ–≤–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
_PLACEHOLDER_PREFIX = "\u0000P"
_PLACEHOLDER_SUFFIX = "\u0000"

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å–ø–ª–∏—Ç–∞
HR_SPLIT_RE = re.compile(
    r"^\s*(\\-\\-\\-|\\\*\\\*\\\*|\\_\\_\\_)\s*$"
)
CODE_FENCE_LINE_RE = re.compile(r"^(`{3,})(.*)$")
BOLD_LINE_RE = re.compile(r"^\s*\*.+\*\s*$")


def _escape_md_v2(text: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã MarkdownV2 –≤–æ –≤—Å—ë–º —Ç–µ–∫—Å—Ç–µ.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è "–≥–æ–ª–æ–≥–æ" —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏.
    """
    return re.sub(r"([_*[\]()~`>#+\-=|{}.!])", r"\\\1", text)


def _escape_md_v2_code(text: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –≤–Ω—É—Ç—Ä–∏ –∫–æ–¥–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤/–∏–Ω–ª–∞–π–Ω-–∫–æ–¥–∞.
    –í Telegram –≤–Ω—É—Ç—Ä–∏ –∫–æ–¥–∞ –Ω—É–∂–Ω–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ backslash –∏ `.
    """
    return text.replace("\\", "\\\\").replace("`", "\\`")


def _escape_md_v2_link_url(url: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç URL –≤–Ω—É—Ç—Ä–∏ () —á–∞—Å—Ç–∏ —Å—Å—ã–ª–∫–∏.
    """
    return re.sub(r"([()])", r"\\\1", url)




def _new_placeholder(store: Dict[str, str], value: str) -> str:
    """
    –°–æ–∑–¥–∞—ë—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏.
    """
    key = f"{_PLACEHOLDER_PREFIX}{len(store)}{_PLACEHOLDER_SUFFIX}"
    store[key] = value
    return key


def _process_inline(text: str) -> str:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–Ω–ª–∞–π–Ω–æ–≤–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π MarkdownV2.
    –õ–æ–≥–∏–∫–∞:
      1. –í—ã–∫—É—Å—ã–≤–∞–µ–º "–æ—Å–æ–±—ã–µ" –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (–∫–æ–¥, —Å—Å—ã–ª–∫–∏, –∂–∏—Ä–Ω—ã–π, –∫—É—Ä—Å–∏–≤, –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ,
         –∑–∞—á—ë—Ä–∫–Ω—É—Ç—ã–π, —Å–ø–æ–π–ª–µ—Ä) –∏ –∑–∞–º–µ–Ω—è–µ–º –∏—Ö –Ω–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã.
      2. –û—Å—Ç–∞–≤—à–∏–π—Å—è plain text —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º _escape_md_v2.
      3. –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –æ–±—Ä–∞—Ç–Ω–æ.
    """
    placeholders: Dict[str, str] = {}
    processed = text

    # –°–ø–µ—Ü-–∫–µ–π—Å: ~~`code`~~ -> `code`
    def repl_strike_code(m: re.Match) -> str:
        inner = _escape_md_v2_code(m.group(1))
        return _new_placeholder(placeholders, f"`{inner}`")

    processed = re.sub(r"~~\s*`([^`]+)`\s*~~", repl_strike_code, processed)

    # –ò–Ω–ª–∞–π–Ω-–∫–æ–¥ `code`
    def repl_code(m: re.Match) -> str:
        inner = _escape_md_v2_code(m.group(1))
        return _new_placeholder(placeholders, f"`{inner}`")

    processed = re.sub(r"`([^`]+)`", repl_code, processed)

    # –£–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º —Å–∏–º–≤–æ–ª—ã markdown: \* \_ \# ...
    def repl_md_escape(m: re.Match) -> str:
        return m.group(1)

    processed = re.sub(r"\\([_*[\]()~`>#+\-=|{}.!])", repl_md_escape, processed)

    # –§–æ—Ä–º—É–ª—ã $...$ -> –∏–Ω–ª–∞–π–Ω-–∫–æ–¥ `...`
    def repl_formula(m: re.Match) -> str:
        inner = _escape_md_v2_code(m.group(1).strip())
        return _new_placeholder(placeholders, f"`{inner}`")

    processed = FORMULA_INLINE_RE.sub(repl_formula, processed)

    # –°—Å—ã–ª–∫–∏ [text](url) –∏ ![alt](url
    def repl_link(m: re.Match) -> str:
        text_inner = _escape_md_v2(m.group(1))
        body = m.group(2).strip()

        # –ï—Å—Ç—å –ª–∏ title?
        m_title = re.match(r'(\S+)\s+"([^"]+)"$', body)
        if m_title:
            url_raw = m_title.group(1)
            title = m_title.group(2)

            title_text = _escape_md_v2(title)
            title_suffix = f" \\({title_text}\\)"
        else:
            url_raw = body
            title_suffix = ""

        url_inner = _escape_md_v2_link_url(url_raw)

        link_md = f"[{text_inner}]({url_inner}){title_suffix}"
        return _new_placeholder(placeholders, link_md)

    processed = LINK_RE.sub(repl_link, processed)

    # –ú–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω—ã–µ –∑–≤—ë–∑–¥–æ—á–∫–∏ ***text***, ****text****, *****text***** ...
    # –ß—ë—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ -> bold (*text*), –Ω–µ—á—ë—Ç–Ω–æ–µ -> italic (_text_)
    def repl_multi_stars(m: re.Match) -> str:
        stars = m.group(1)
        inner_raw = m.group(2)
        count = len(stars)
        inner = _escape_md_v2(inner_raw)

        if count % 2 == 0:
            # —á—ë—Ç–Ω–æ–µ -> –∂–∏—Ä–Ω—ã–π
            return _new_placeholder(placeholders, f"*{inner}*")
        else:
            # –Ω–µ—á—ë—Ç–Ω–æ–µ -> –∫—É—Ä—Å–∏–≤
            return _new_placeholder(placeholders, f"_{inner}_")

    # (\*{3,}) - –ª–µ–≤–∞—è –≥—Ä—É–ø–ø–∞ –∏–∑ 3+ –∑–≤—ë–∑–¥–æ—á–µ–∫, \1 - —Ç–∞–∫–∞—è –∂–µ —Å–ø—Ä–∞–≤–∞
    processed = re.sub(r"(\*{3,})(.+?)\1", repl_multi_stars, processed)

    # –ñ–∏—Ä–Ω—ã–π **text** -> *text*
    def repl_bold(m: re.Match) -> str:
        inner = _escape_md_v2(m.group(1))
        return _new_placeholder(placeholders, f"*{inner}*")

    processed = re.sub(r"\*\*(.+?)\*\*", repl_bold, processed)

    # –ü–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ __text__ -> __text__
    def repl_underline(m: re.Match) -> str:
        inner = _escape_md_v2(m.group(1))
        return _new_placeholder(placeholders, f"__{inner}__")

    processed = re.sub(r"__(.+?)__", repl_underline, processed)

    # –ö—É—Ä—Å–∏–≤ *text* -> _text_
    # –°—Ç–∞—Ä–∞–µ–º—Å—è –Ω–µ –∑–∞—Ü–µ–ø–∏—Ç—å —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π **bold**
    def repl_italic(m: re.Match) -> str:
        inner = _escape_md_v2(m.group(1))
        return _new_placeholder(placeholders, f"_{inner}_")
    
    # –∫—É—Ä—Å–∏–≤ —á–µ—Ä–µ–∑ –∑–≤—ë–∑–¥–æ—á–∫–∏
    processed = re.sub(r"(?<!\*)\*(?!\*)(.+?)(?<!\*)\*(?!\*)", repl_italic, processed)
    # –∫—É—Ä—Å–∏–≤ —á–µ—Ä–µ–∑ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è
    processed = re.sub(r"(?<!_)_(?!_)(.+?)(?<!_)_(?!_)", repl_italic, processed)

    # –ó–∞—á—ë—Ä–∫–Ω—É—Ç—ã–π ~~text~~ -> ~text~
    def repl_strike(m: re.Match) -> str:
        inner = _escape_md_v2(m.group(1))
        return _new_placeholder(placeholders, f"~{inner}~")

    processed = re.sub(r"~~(.+?)~~", repl_strike, processed)

    # –°–ø–æ–π–ª–µ—Ä ||text|| -> ||text||
    def repl_spoiler(m: re.Match) -> str:
        inner = _escape_md_v2(m.group(1))
        return _new_placeholder(placeholders, f"||{inner}||")

    processed = re.sub(r"\|\|(.+?)\|\|", repl_spoiler, processed)

    # –ù–∞ –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç –Ω–∞–≤–µ—à–∏–≤–∞–µ–º —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    escaped_plain = _escape_md_v2(processed)

    # –ú–Ω–æ–≥–æ—à–∞–≥–æ–≤–æ–µ —Ä–∞—Å–∫—Ä—ã—Ç–∏–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤:
    # –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –º–æ–≥—É—Ç –±—ã—Ç—å –≤–ª–æ–∂–µ–Ω–Ω—ã–º–∏ (–æ–¥–∏–Ω –≤–Ω—É—Ç—Ä–∏ –∑–Ω–∞—á–µ–Ω–∏—è –¥—Ä—É–≥–æ–≥–æ),
    # –ø–æ—ç—Ç–æ–º—É –≥–æ–Ω—è–µ–º –∑–∞–º–µ–Ω—É, –ø–æ–∫–∞ –≤ —Ç–µ–∫—Å—Ç–µ –æ—Å—Ç–∞—é—Ç—Å—è –º–∞—Ä–∫–µ—Ä—ã P\d+.
    placeholder_pattern = re.compile(
        re.escape(_PLACEHOLDER_PREFIX) + r"\d+" + re.escape(_PLACEHOLDER_SUFFIX)
    )

    while placeholder_pattern.search(escaped_plain):
        replaced = escaped_plain
        for key, value in placeholders.items():
            replaced = replaced.replace(key, value)
        if replaced == escaped_plain:
            break
        escaped_plain = replaced

    return escaped_plain


def _is_table_header(line: str) -> bool:
    return bool(TABLE_ROW_RE.match(line))


def _is_table_sep(line: str) -> bool:
    return bool(TABLE_SEP_RE.match(line))


def _split_table_row(line: str) -> List[str]:
    stripped = line.strip()
    if stripped.startswith("|"):
        stripped = stripped[1:]
    if stripped.endswith("|"):
        stripped = stripped[:-1]
    return [cell.strip() for cell in stripped.split("|")]


def _normalize_table_cell(cell: str) -> str:
    """
    –í–Ω—É—Ç—Ä–∏ —Ç–∞–±–ª–∏—Ü —Ä–∞–∑—Ä–µ—à–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ Markdown-—Å–∏–º–≤–æ–ª–æ–≤:
    \* -> *, \_ -> _, \# -> #, \[ -> [, \] -> ]
    –ù–æ –ù–ï —Ç—Ä–æ–≥–∞–µ–º —Ç–∞–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏ inline-code (`...`).
    """
    ESCAPABLE = set("*_#[]")
    result: List[str] = []
    i = 0
    n = len(cell)
    in_code = False

    while i < n:
        ch = cell[i]

        if ch == "`":
            in_code = not in_code
            result.append(ch)
            i += 1
            continue

        if not in_code and ch == "\\" and i + 1 < n and cell[i + 1] in ESCAPABLE:
            # \* -> *
            result.append(cell[i + 1])
            i += 2
            continue

        result.append(ch)
        i += 1

    return "".join(result)


def _render_table_block(lines: List[str]) -> List[str]:
    """
    –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –≤ –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω—É—é –ø—Å–µ–≤–¥–æ—Ç–∞–±–ª–∏—Ü—É –≤ –∫–æ–¥–æ–≤–æ–º –±–ª–æ–∫–µ.
    """
    parsed_rows: List[List[str]] = []

    for idx, ln in enumerate(lines):
        # –≤—Ç–æ—Ä—É—é —Å—Ç—Ä–æ–∫—É —Å :---|:---|:--- —Å—á–∏—Ç–∞–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if idx == 1 and _is_table_sep(ln):
            continue
        raw_cells = _split_table_row(ln)
        normalized_cells = [_normalize_table_cell(c) for c in raw_cells]
        parsed_rows.append(normalized_cells)

    if not parsed_rows:
        # fallback: –ø—Ä–æ—Å—Ç–æ –æ—Ç–¥–∞—Ç—å –∫–∞–∫ –µ—Å—Ç—å, —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–≤
        return ["```"] + [_escape_md_v2_code(ln) for ln in lines] + ["```"]

    max_cols = max(len(r) for r in parsed_rows)
    for r in parsed_rows:
        if len(r) < max_cols:
            r.extend([""] * (max_cols - len(r)))

    # —à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫ –ø–æ max –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ
    widths = [max(len(c) for c in col) for col in zip(*parsed_rows)]

    text_rows: List[str] = []

    # –∑–∞–≥–æ–ª–æ–≤–æ–∫
    header = parsed_rows[0]
    header_line = " | ".join(c.ljust(widths[i]) for i, c in enumerate(header))
    text_rows.append(header_line)

    # —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    sep_line = "-+-".join("-" * widths[i] for i in range(max_cols))
    text_rows.append(sep_line)

    # –¥–∞–Ω–Ω—ã–µ
    for row in parsed_rows[1:]:
        text_rows.append(" | ".join(c.ljust(widths[i]) for i, c in enumerate(row)))

    # –∑–∞–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –≤—Å—ë –≤ –∫–æ–¥–æ–≤—ã–π –±–ª–æ–∫
    out: List[str] = ["```"]
    out.extend(_escape_md_v2_code(r) for r in text_rows)
    out.append("```")
    return out


def convert_to_md_v2(text: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç "–æ–±—ã—á–Ω—ã–π" markdown (–∫–∞–∫ –µ–≥–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç LLM) –≤ Telegram MarkdownV2.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
      - #..###### –∑–∞–≥–æ–ª–æ–≤–∫–∏ -> –∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç
      - **bold**
      - *italic*
      - _italic_
      - __underline__
      - ~~strike~~
      - ||spoiler||
      - `inline code`
      - ```code blocks``` (–≤–∫–ª—é—á–∞—è –≤–Ω–µ—à–Ω–∏–µ ````markdown ... ````)
      - $inline-—Ñ–æ—Ä–º—É–ª—ã$ -> `inline`
      - –±–ª–æ—á–Ω—ã–µ —Ñ–æ—Ä–º—É–ª—ã \n$...$\n –∏ $$...$$ -> –∫–æ–¥–æ–≤—ã–π –±–ª–æ–∫
      - [text](url) –∏ ![alt](url
      - > —Ü–∏—Ç–∞—Ç—ã
      - —Ç–∞–±–ª–∏—Ü—ã -> –ø—Å–µ–≤–¥–æ—Ç–∞–±–ª–∏—Ü–∞ –≤ –∫–æ–¥–æ–≤–æ–º –±–ª–æ–∫–µ
    """
    lines = text.splitlines()
    out_lines: List[str] = []

    in_code_block = False
    code_fence_len = 0

    i = 0
    n = len(lines)

    while i < n:
        raw_line = lines[i]
        line = raw_line
        stripped = line.lstrip()

        # –µ—Å–ª–∏ —É–∂–µ –≤–Ω—É—Ç—Ä–∏ –∫–æ–¥–æ–≤–æ–≥–æ –±–ª–æ–∫–∞
        if in_code_block:
            # –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–∫—Ä—ã—Ç—å –∫–æ–¥–æ–≤—ã–π –±–ª–æ–∫?
            if stripped.startswith("```"):
                m = re.match(r"^(`{3,})(.*)$", stripped)
                if m:
                    fence, _ = m.groups()
                    fence_len = len(fence)
                    if fence_len == code_fence_len:
                        in_code_block = False
                        code_fence_len = 0
                        out_lines.append("```")
                        i += 1
                        continue
            # –æ–±—ã—á–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –∫–æ–¥–∞
            out_lines.append(_escape_md_v2_code(line))
            i += 1
            continue

        # –¥–µ—Ç–µ–∫—Ç —Ç–∞–±–ª–∏—Ü—ã
        if _is_table_header(line) and i + 1 < n and _is_table_sep(lines[i + 1]):
            table_lines: List[str] = []
            j = i
            while j < n and TABLE_ROW_RE.match(lines[j]):
                table_lines.append(lines[j])
                j += 1

            out_lines.extend(_render_table_block(table_lines))
            i = j
            continue

        # –¥–µ—Ç–µ–∫—Ç —Ñ–æ—Ä–º—É–ª—ã
        if stripped == "$$":
            j = i + 1
            formula_lines: List[str] = []

            # —Å–æ–±–∏—Ä–∞–µ–º –≤—Å—ë –¥–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–∏ —Å $$ –∏–ª–∏ –∫–æ–Ω—Ü–∞ —Ç–µ–∫—Å—Ç–∞
            while j < n and lines[j].strip() != "$$":
                formula_lines.append(lines[j])
                j += 1

            # —Ä–µ–Ω–¥–µ—Ä–∏–º –∫–∞–∫ –∫–æ–¥–æ–≤—ã–π –±–ª–æ–∫
            out_lines.append("```")
            for fl in formula_lines:
                out_lines.append(_escape_md_v2_code(fl))
            out_lines.append("```")

            # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é $$, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
            if j < n and lines[j].strip() == "$$":
                i = j + 1
            else:
                i = j
            continue

        # –±–ª–æ—á–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞: $$ ... $$
        m_dbl_block = FORMULA_DBL_BLOCK_RE.match(line)
        if m_dbl_block:
            inner_raw = m_dbl_block.group(1).strip()
            code_line = _escape_md_v2_code(inner_raw)
            out_lines.append("```")
            out_lines.append(code_line)
            out_lines.append("```")
            i += 1
            continue

        # –±–ª–æ—á–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞: \n$ ... \n$
        m_formula_block = FORMULA_BLOCK_RE.match(line)
        if m_formula_block:
            inner_raw = m_formula_block.group(1).strip()
            code_line = _escape_md_v2_code(inner_raw)
            out_lines.append("```")
            out_lines.append(code_line)
            out_lines.append("```")
            i += 1
            continue

        # –∫–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏ ```...``` / ````...```
        if stripped.startswith("```"):
            m = re.match(r"^(`{3,})(.*)$", stripped)
            if m:
                fence, rest = m.groups()
                fence_len = len(fence)

                # –æ—Ç–∫—Ä—ã–≤–∞–µ–º –Ω–æ–≤—ã–π –±–ª–æ–∫ –∫–æ–¥–∞
                in_code_block = True
                code_fence_len = fence_len

                lang = rest.strip()
                if lang:
                    out_lines.append(f"```{lang}")
                else:
                    out_lines.append("```")

                i += 1
                continue

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ #..###### ---
        m = HEADER_RE.match(line)
        if m:
            content = m.group(2).strip()
            inner = _process_inline(content)
            out_lines.append(f"*{inner}*")
            i += 1
            continue

        # –¶–∏—Ç–∞—Ç—ã >
        if stripped.startswith(">"):
            m_quote = re.match(r"^\s*(>+)\s?(.*)$", line)
            if m_quote:
                quote_marks = m_quote.group(1)   # '>', '>>', '>>>'
                content = m_quote.group(2) or "" # —Ç–µ–∫—Å—Ç –±–µ–∑ '>'
                inner = _process_inline(content) if content else ""
                if inner:
                    out_lines.append(f"{quote_marks} {inner}")
                else:
                    out_lines.append(quote_marks)
                i += 1
                continue

        # –û–±—ã—á–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –∏–Ω–ª–∞–π–Ω–æ–≤—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        out_lines.append(_process_inline(line))
        i += 1

    # –µ—Å–ª–∏ LLM –æ—Ç–∫—Ä—ã–ª –±–ª–æ–∫ –∫–æ–¥–∞ –∏ –Ω–µ –∑–∞–∫—Ä—ã–ª - –∑–∞–∫—Ä–æ–µ–º –∑–∞ –Ω–µ–≥–æ
    if in_code_block:
        out_lines.append("```")

    return "\n".join(out_lines)


def _split_on_horizontal_rules(text: str) -> List[str]:
    """
    –î–µ–ª–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å–µ–∫—Ü–∏–∏ –ø–æ —Å—Ç—Ä–æ–∫–∞–º-—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º:

      ---
      ***
      ___

    –≠—Ç–∏ —Å—Ç—Ä–æ–∫–∏ –≤ –≤—ã–≤–æ–¥ –Ω–µ –ø–æ–ø–∞–¥–∞—é—Ç.
    """
    lines = text.splitlines(keepends=True)
    sections: List[str] = []
    buf: List[str] = []

    for line in lines:
        if HR_SPLIT_RE.match(line.strip()):
            if buf:
                sections.append("".join(buf).rstrip())
                buf = []
            # —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –≤—ã–∫–∏–¥—ã–≤–∞–µ–º
            continue
        buf.append(line)

    if buf:
        sections.append("".join(buf).rstrip())

    return sections


def _parse_blocks(section: str) -> List[Dict[str, str]]:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Å–µ–∫—Ü–∏—é –Ω–∞ –±–ª–æ–∫–∏ –¥–≤—É—Ö —Ç–∏–ø–æ–≤:
      - {"type": "text", "text": "..."}
      - {"type": "code", "text": "```lang\\n...```"}
    """
    lines = section.splitlines(keepends=True)
    blocks: List[Dict[str, str]] = []

    i = 0
    n = len(lines)

    while i < n:
        line = lines[i]
        stripped = line.lstrip()
        m = CODE_FENCE_LINE_RE.match(stripped)

        if m:
            # –ë–ª–æ–∫ –∫–æ–¥–∞ c ```...```
            opening = lines[i]
            i += 1
            body_lines: List[str] = []

            # –°–æ–±–∏—Ä–∞–µ–º –¥–æ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–≥–æ ```
            while i < n:
                l2 = lines[i]
                if l2.lstrip().startswith("```"):
                    closing = l2
                    i += 1
                    break
                body_lines.append(l2)
                i += 1
            else:
                closing = ""

            full_block = opening + "".join(body_lines) + closing
            blocks.append({"type": "code", "text": full_block})
        else:
            # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ ``` –∏–ª–∏ –∫–æ–Ω—Ü–∞
            text_lines = [line]
            i += 1
            while i < n and not CODE_FENCE_LINE_RE.match(lines[i].lstrip()):
                text_lines.append(lines[i])
                i += 1
            blocks.append({"type": "text", "text": "".join(text_lines)})

    return blocks


def _smart_split_point(text: str, max_len: int) -> int:
    """
    –ò—â–µ—Ç "–∫—Ä–∞—Å–∏–≤—É—é" –ø–æ–∑–∏—Ü–∏—é —Ä–∞–∑—Ä—ã–≤–∞ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö max_len (–¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞).

    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–µ–ª–µ–Ω–∏—è:
      - –ø–æ –¥–≤–æ–π–Ω—ã–º –ø–µ—Ä–µ–≤–æ–¥–∞–º —Å—Ç—Ä–æ–∫ (\n\n)
      - –ø–æ –æ–¥–∏–Ω–æ—á–Ω–æ–º—É –ø–µ—Ä–µ–≤–æ–¥—É —Å—Ç—Ä–æ–∫–∏ (\n)
      - –ø–æ —Ç–∞–±—É–ª—è—Ü–∏–∏ (\t)
      - –ø–æ —Ç–æ—á–∫–∞+–ø—Ä–æ–±–µ–ª (". ")
      - –ø–æ –ø—Ä–æ–±–µ–ª—É
      - –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ - –∂—ë—Å—Ç–∫–æ —Ä–µ–∂–µ–º –Ω–∞ max_len
    """
    if len(text) <= max_len:
        return len(text)

    window = text[:max_len]

    # \n\n
    idx = window.rfind("\n\n")
    if idx != -1:
        return idx + 2

    # \n
    idx = window.rfind("\n")
    if idx != -1:
        return idx + 1

    # \t
    idx = window.rfind("\t")
    if idx != -1:
        return idx + 1

    # ". "
    idx = window.rfind(". ")
    if idx != -1:
        return idx + 2

    # –ø—Ä–æ–±–µ–ª
    idx = window.rfind(" ")
    if idx != -1:
        return idx + 1

    # –∂—ë—Å—Ç–∫–∏–π —Ä–∞–∑—Ä–µ–∑
    return max_len


def _smart_split_point_code(text: str, max_len: int) -> int:
    """
    "–ö—Ä–∞—Å–∏–≤—ã–π" —Ä–∞–∑—Ä—ã–≤ –¥–ª—è –∫–æ–¥–∞ (–±–µ–∑ —Ç–æ—á–∫–∏-–ø—Ä–æ–±–µ–ª–∞).
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
      - \n\n
      - \n
      - \t
      - –ø—Ä–æ–±–µ–ª
      - –∏–Ω–∞—á–µ –∂—ë—Å—Ç–∫–∏–π —Ä–∞–∑—Ä–µ–∑
    """
    if len(text) <= max_len:
        return len(text)

    window = text[:max_len]

    idx = window.rfind("\n\n")
    if idx != -1:
        return idx + 2

    idx = window.rfind("\n")
    if idx != -1:
        return idx + 1

    idx = window.rfind("\t")
    if idx != -1:
        return idx + 1

    idx = window.rfind(" ")
    if idx != -1:
        return idx + 1

    return max_len


def _split_long_code_block(block_text: str, limit: int) -> List[str]:
    """
    –î–µ–ª–∏—Ç –æ–¥–∏–Ω –∫–æ–¥–æ–≤—ã–π –±–ª–æ–∫ (—Å —É–∂–µ —Ä–∞—Å—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º–∏ ```...```) –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ
    —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–¥-–±–ª–æ–∫–æ–≤, –µ—Å–ª–∏ –æ–Ω —Å–∞–º –ø–æ —Å–µ–±–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç limit.

    –ö–∞–∂–¥—ã–π –∫—É—Å–æ–∫ –±—É–¥–µ—Ç –∏–º–µ—Ç—å —Å–≤–æ–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ:
      ```lang
      ...—á–∞—Å—Ç—å –∫–æ–¥–∞...
      ```
    """
    lines = block_text.splitlines(keepends=True)
    if not lines:
        return []

    # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - header —Å ```lang
    header = lines[0]

    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É, –Ω–∞—á–∏–Ω–∞—é—â—É—é—Å—è —Å ```
    footer_idx = None
    for idx in range(len(lines) - 1, -1, -1):
        if lines[idx].lstrip().startswith("```"):
            footer_idx = idx
            break

    if footer_idx is None:
        body_lines = lines[1:]
        footer = ""
    else:
        body_lines = lines[1:footer_idx]
        footer = lines[footer_idx]

    header_len = len(header)
    footer_len = len(footer)
    max_body = max(1, limit - header_len - footer_len)

    body_text = "".join(body_lines)
    chunks: List[str] = []

    rest = body_text
    while rest:
        if len(rest) <= max_body:
            part = rest
            rest = ""
        else:
            split_at = _smart_split_point_code(rest, max_body)
            part = rest[:split_at]
            rest = rest[split_at:]

        chunks.append(header + part + footer)

    return chunks


def _detach_last_bold_line(text: str) -> (str, str):
    """
    –ò—â–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é "–∂–∏—Ä–Ω—É—é" —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ *–ó–∞–≥–æ–ª–æ–≤–æ–∫*,
    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (prefix, bold_tail), –≥–¥–µ:

      text = prefix + bold_tail

    –ï—Å–ª–∏ –∂–∏—Ä–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –Ω–µ—Ç - bold_tail == "".
    """
    lines = text.splitlines(keepends=True)
    for idx in range(len(lines) - 1, -1, -1):
        line = lines[idx]
        if BOLD_LINE_RE.match(line.strip()):
            prefix = "".join(lines[:idx])
            bold_tail = "".join(lines[idx:])
            return prefix, bold_tail
    return text, ""


def _append_text_block(
    chunks: List[str],
    current: str,
    block_text: str,
    limit: int,
) -> (List[str], str):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ –≤ —Ç–µ–∫—É—â–∏–π chunk —Å —É—á—ë—Ç–æ–º –ª–∏–º–∏—Ç–∞.
    –ï—Å–ª–∏ –±–ª–æ–∫ –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è, —Ä–µ–∂–µ—Ç –µ–≥–æ –ø–æ _smart_split_point().
    """
    text = block_text

    while text:
        remaining = limit - len(current)
        if remaining <= 0:
            # –¢–µ–∫—É—â–∏–π chunk –∑–∞–ø–æ–ª–Ω–µ–Ω - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏ –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π
            if current.strip():
                chunks.append(current.rstrip())
            current = ""
            remaining = limit

        # –≤—Å—ë —Ü–µ–ª–∏–∫–æ–º –ø–æ–º–µ—â–∞–µ—Ç—Å—è
        if len(text) <= remaining:
            current += text
            break

        # –Ω—É–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞
        split_at = _smart_split_point(text, remaining)
        # –∑–∞—â–∏—Ç–∞ –æ—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è
        if split_at <= 0:
            # –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è - –≤—ã–Ω—É–∂–¥–µ–Ω–Ω–æ —Ä–µ–∂–µ–º –∂—ë—Å—Ç–∫–æ
            split_at = remaining

        current += text[:split_at]
        if current.strip():
            chunks.append(current.rstrip())
        current = ""
        text = text[split_at:].lstrip()

    return chunks, current


def _append_code_block(
    chunks: List[str],
    current: str,
    block_text: str,
    limit: int,
) -> (List[str], str):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–¥–æ–≤—ã–π –±–ª–æ–∫ –≤ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Å —É—á—ë—Ç–æ–º –ø—Ä–∞–≤–∏–ª:
      - –µ—Å–ª–∏ –±–ª–æ–∫ –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ –æ—Å—Ç–∞—Ç–æ–∫ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è,
        –ø–µ—Ä–µ–Ω–æ—Å–∏–º –µ–≥–æ –≤ –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ;
      - –ø—Ä–∏ –ø–µ—Ä–µ–Ω–æ—Å–µ –∏—â–µ–º –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â—É—é —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ *–ó–∞–≥–æ–ª–æ–≤–æ–∫* –∏
        –ø–µ—Ä–µ–Ω–æ—Å–∏–º –µ—ë –≤–º–µ—Å—Ç–µ —Å –±–ª–æ–∫–æ–º –≤ –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ;
      - –µ—Å–ª–∏ —Å–∞–º –∫–æ–¥–æ–≤—ã–π –±–ª–æ–∫ > limit, –¥–µ–ª–∏–º –µ–≥–æ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã—Ö
        –∫–æ–¥-–±–ª–æ–∫–æ–≤ (—Å–º. _split_long_code_block).
    """
    # –ë–ª–æ–∫ —Å–∞–º –ø–æ —Å–µ–±–µ –¥–ª–∏–Ω–Ω–µ–µ –ª–∏–º–∏—Ç–∞ -> –¥–µ–ª–∏–º –µ–≥–æ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ
    if len(block_text) > limit:
        bold_tail = ""
        if current:
            prefix, bold_tail = _detach_last_bold_line(current)
            if prefix.strip():
                chunks.append(prefix.rstrip())
            current = ""  # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω—ã–π bold_tail –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∏–∂–µ

        pieces = _split_long_code_block(block_text, limit)
        first = True
        for piece in pieces:
            piece = piece.rstrip()
            if first and bold_tail:
                merged = bold_tail + piece
                if len(merged) <= limit:
                    chunks.append(merged.rstrip())
                else:
                    # –Ω–µ –ø–æ–º–µ—Å—Ç–∏–ª—Å—è –≤–º–µ—Å—Ç–µ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç–¥–µ–ª—å–Ω–æ
                    chunks.append(bold_tail.rstrip())
                    chunks.append(piece)
                bold_tail = ""
                first = False
            else:
                chunks.append(piece)
        return chunks, current

    # –ë–ª–æ–∫ —É–º–µ—â–∞–µ—Ç—Å—è –≤ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
    if len(current) + len(block_text) <= limit:
        # –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –∫ —Ç–µ–∫—É—â–µ–º—É
        current += block_text
        return chunks, current

    # –ë–ª–æ–∫ –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ –æ—Å—Ç–∞—Ç–æ–∫ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è -> –Ω–æ–≤—ã–π chunk
    bold_tail = ""
    if current:
        prefix, bold_tail = _detach_last_bold_line(current)
        if prefix.strip():
            chunks.append(prefix.rstrip())
        # bold_tail –ø–æ–π–¥—ë—Ç –≤ –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–º–µ—Å—Ç–µ —Å –∫–æ–¥–æ–º
        current = ""

    new_chunk = (bold_tail + block_text).rstrip()
    chunks.append(new_chunk)
    return chunks, ""


def _split_section(section: str, limit: int) -> List[str]:
    """
    –°–ø–ª–∏—Ç–∏—Ç –æ–¥–Ω—É ¬´–ª–æ–≥–∏—á–µ—Å–∫—É—é —Å–µ–∫—Ü–∏—é¬ª (–º–µ–∂–¥—É ---/***/___) –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è.
    """
    blocks = _parse_blocks(section)
    chunks: List[str] = []
    current = ""

    for blk in blocks:
        if blk["type"] == "text":
            chunks, current = _append_text_block(chunks, current, blk["text"], limit)
        else:
            chunks, current = _append_code_block(chunks, current, blk["text"], limit)

    if current.strip():
        chunks.append(current.rstrip())

    return chunks


def split_md_v2(text: str, limit: int = MAX_TELEGRAM_MESSAGE_LEN) -> List[str]:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π Telegram.MarkdownV2-—Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏, –∫–∞–∂–¥–∞—è –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö
    —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç Telegram –ø–æ –¥–ª–∏–Ω–µ.

    –ü—Ä–∞–≤–∏–ª–∞:
      1. –°—Ç—Ä–æ–∫–∏ –∏–∑ `---`, `***`, `___` (–æ–∫—Ä—É–∂—ë–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ —Å—Ç—Ä–æ–∫) –¥–µ–ª—è—Ç —Ç–µ–∫—Å—Ç
         –Ω–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ —Å–µ–∫—Ü–∏–∏.
      2. –ü—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–∞ —Ç–µ–∫—Å—Ç–∞ –≤–Ω—É—Ç—Ä–∏ —Å–µ–∫—Ü–∏–∏:
         - —Ç–µ–∫—Å—Ç —Ä–µ–∂–µ—Ç—Å—è –ø–æ "–∫—Ä–∞—Å–∏–≤—ã–º" –ø–æ–∑–∏—Ü–∏—è–º (_smart_split_point);
         - –∫–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏ –ª–∏–±–æ —Ü–µ–ª–∏–∫–æ–º –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è –≤ –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
           –≤–º–µ—Å—Ç–µ —Å –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏–º –∂–∏—Ä–Ω—ã–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º (*–ó–∞–≥–æ–ª–æ–≤–æ–∫*),
           –ª–∏–±–æ –¥–µ–ª—è—Ç—Å—è –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–¥-–±–ª–æ–∫–æ–≤,
           –µ—Å–ª–∏ –æ–Ω–∏ —Å–∞–º–∏ –ø—Ä–µ–≤—ã—à–∞—é—Ç –ª–∏–º–∏—Ç.
      3. –í –∫–æ–Ω—Ü–µ –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è `strip()`-—è—Ç—Å—è; –ø—É—Å—Ç—ã–µ/–ø—Ä–æ–±–µ–ª—å–Ω—ã–µ –æ—Ç–±—Ä–∞—Å—ã–≤–∞—é—Ç—Å—è.
    """
    # –°–Ω–∞—á–∞–ª–∞ –¥–µ–ª–∏–º –Ω–∞ —Å–µ–∫—Ü–∏–∏ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º
    sections = _split_on_horizontal_rules(text)

    all_chunks: List[str] = []
    for sec in sections:
        if not sec.strip():
            continue
        all_chunks.extend(_split_section(sec, limit))

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞: —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º –∏ –ø—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    result: List[str] = []
    for ch in all_chunks:
        cleaned = ch.strip()
        if cleaned:
            result.append(cleaned)

    return result
```


